# Relatório de Estudos

**Nome do Estagiáro:** Melina Nogueira

**Data:** 07/08/2024

**Módulos/Etapas Feitas:**  
1. **[Big Data:](#big-data)** Conceitos e aplicações.
2. **[Engenharia de Dados:](#engenharia-de-dados)** Conceitos, ferramentas, linguagens e termos.
3. **[Modelagem de Dados:](#modelagem-de-dados)** Conceitos, tipos, processo e ferramentas.
4. **[Análise de Dados:](#análise-de-dados)** Conceitos, processo e ferramentas.
5. **[Analítico:](#analítico)** Conceitos, características e tecnologias.
6. **[Apache Spark:](#apache-spark)** Conceitos, componentes e arquitetura.
7. **[BigQuery:](#bigquery)** Conceitos
8. **[Microsoft Azure:](#microsoft-azure)** Conceitos e serviços.
8. **[Termos](#termos)**

## Resumo dos módulos

### Big Data

#### O que é
Conjunto de tecnologias e práticas para coletar, armazenar, processar e analisar grandes volumes de dados, não podem ser gerenciados de maneira eficiente pelas ferramentas tradicionais do banco de dados.

#### 4 V's
1. Volume: quantidade de dados;
2. Variedade: tipos de dados (estruturados, semiestruturados ou não estruturados);
3. Velocidade: velocidade com que novos dados são gerados e precisam ser processados;
4. Veracidade: qualidade e confiabilidade dos dados.

#### Aplicações
- Negócios: análise comportamento do consumidor
- Saúde: monitoramento de epidemia
- Ciência: estudos climáticos


### Engenharia de Dados

#### O que é
Criação e manutenção de sistemas e infraestruturas para coletar, armazenar, processar e analisar um grande volume de dados. Ele é importante para transformar dados brutos em informações úteis que podem ser utilizadas para tomar decisões, analisar negócios e desenvolver modelos de Machine Learning.

Coleta de dados → desenvolver soluções pra armazenamento → transformar e limpeza dos dados → juntar os dados → criar [pipelines](#pipelines "cadeia de elementos de processamento") → armazenamento e segurança dos dados.

#### Ferramentas
*MySQL*, *PostgreSQL*, *MongoDB*, *Google BigQuery*, Cassandra, Amazon Redshift, Airbyte, Dataflow, Apache Hadoop, Apache Spark, Apache Flink, Apache Nifi, Apache Airflow;

#### Linguagens
 *Python*, *SQL*, *Java*, Scala, R.

### Modelagem de Dados

#### O que é
Criar um modelo para os dados que serão utilizados em um sistema de informação. O modelo define a estrutura lógica e as relações entre os diferentes tipos de dados, que serve como base para a construção de banco de dados e sistemas de gerenciamento de informações.

#### Tipos
1. **Modelo Conceitual:** visão de alto nível dos requisitos de dados do negócio, foco na organização e definição dos principais conceitos e relações, sem considerar os detalhes técnicos;
2. **Modelo Lógico:** detalha o modelo conceitual para descrever a estrutura lógica dos dados, como tipo de dados, atributos e as relações entre entidades;
3. **Modelo Físico:** define como o modelo lógico vai ser implementado num sistema de banco de dados específico, incluindo detalhes e aspectos técnicos.

#### Processo
1. **Coleta de Requisitos:** identificar e documentar os requisitos com base nas necessidades do negócio;
2. **Criação do Modelo Conceitual:** representar entidades e relações;
3. **Criação do Modelo Lógico:** adicionar atributos, tipos de dados e relacionamentos no modelo conceitual;
4. **Criação do Modelo Físico:** converter o modelo lógico em um esquema de banco de dados, especificando detalhes de implementação;
5. **Validação e Refinamento:** verificar se o modelo atende os requisitos e realizar ajustes se necessário;
6. **Implementação:** implementar o modelo físico em um sistema de banco de dados e configurar os dados de acordo com o modelo.

#### Ferramentas
- ER/Studio
- IBM InfoSphere Data Architect
- Microsoft Visio
- Oracle SQL Developer Data Modeler
- PowerDesigner
- MySQL Workbench

### Análise de dados

#### O que é
Processo de inspecionar, limpar e modelar dados para descobrir informações úteis, tirar conclusões e apoiar tomada de decisões.

#### Processo
- **Coleta de Dados:** reunir dados de diferentes fontes e garantir que os dados sejam relevantes e representativos para a análise;
- **Preparação e Limpeza de Dados:** limpeza de dados sujos, eliminar dados duplicaods, tratamento de valores ausentes, formatação de dados e garantir que os dados sejam precisos, consistentes e prontos para análise;
- **Exploração de Dados:** visão geral dos dados, identificar tendências, padrões e anomalias;
- **Análise Descritiva:** descrever as características dos dados por meio de estatísticas e visualizações;
- **Análise Diagnóstica:** investiga o motivo pelo qual um evento ou tendência ocorreu, análise de correlações e identificação de causas potenciais;
- **Análise Preditiva:** prever futuros eventos (a demanda de produtos, o comportamento do cliente ou a probabilidade de ocorrência de certos eventos) com base em dados históricos;
- **Análise Prescritiva:** sugere ações para alcançar um resultado desejado, utilizando modelos e simulações para fazer as sugestões;
- **Visualização de Dados:** [representação gráfica](#representacao-grafica "gráficos, tabelas, mapas, etc") de dados para facilitar a compreensão e a interpretação;
- **Modelagem de Dados:** construção de modelos matemáticos ou estatísticos para representar e analisar os dados, utilizando técnicas como regressão, [clustering](#clustering "organizar dados por meio do agrupamento em conjuntos") e análise de séries temporais;
- **Interpretação e Comunicação:** analisar e comunicar os [insights](#insights "encontrar soluções para elaborar estratégias e as tomadas de decisão") obtidos dos dados.

#### Ferramentas

- **Ferramentas de Análise:** *Excel*, R, *Python (pandas, numpy), SQL*, Tableau, Power BI e Google Data Studio.
- **Técnicas Estatísticas:** *testes de hipóteses*, análise de regressão, análise de variância (ANOVA), correlação e outras técnicas estatísticas.
- **Algoritmos de Machine Learning:** regressão, árvores de decisão, redes neurais, clustering (k-means, DBSCAN) e outros.

### Analítico

#### O que é
Bases analíticas referem-se a sistemas e tecnologias projetados para facilitar a análise de grandes volumes de dados. As bases analíticas são usadas em conjunto com [data warehouse](#data-warehouse "repositório central de informações, integração e estruturação de dados de várias fontes para análise e relatórios") e [data lakes](#data-lake "repositório centralizado que ingere, armazena e permite o processamento de grandes volumes de dados em sua forma original") para suportar diversas necessidades de análises de dados.

#### Características
1. Desempenho de Consultas: executar consultas complexas e pesadas de maneira rápida e eficiente;
2. Escalabilidade: lidar com grande volumes de dados e aumentar a capacidade se necessário;
3. Integração de Dados: integração de dados de múltiplas fontes e tipos;
4. Modelagem de Dados: organizar e relacionar informações de maneira lógica e acessível;
5. Ferramentas de análise: ferramentas para mineração de dados, machine learning, visualização de dados e análise estatística.

#### Tecnologias
- **OLAP (Online Analytical Processing)**
- **Apache Spark**
- **Google BigQuery**
- **Amazon Redshift**
- **Microsoft Azure Synapse Analytics**

### Apache Spark

#### O que é
Mecanismo de análise para processamento de dados em grande escala com módulos integrados para SQL, streaming, machine learning e processamento gráficos.

#### Componentes
- **Spark Core:** mecanismo de processamento de dados distribuídos de uso geral;
- **Spark SQL:** módulo para trabalhar com dados estruturados, oferece suporte ao acesso de uma varidade de fontes de dados, além de permitir consultar dados dentro de programas Spark;
- **Spark Streaming:** facilita criação de soluções de streaming escalonáveis e tolerantes a falhas;
- **MLlib:** biblioteca de machine learning escalonável do Spark, tornando a ML prática escalonável e fácil;
- **GraphX**: API Spark para gráficos e computação paralela a gráficos. Ela extrai, transforma, carrega, faz análise exploratória e a computação gráfica iterativa.

#### Componentes Modelo de Programação
1. **Resilient Distributed Dataset (RDD):** são estruturas utilizadas em memória e representa uma coleção de dados que são imutáveis;

2. **Operações:** representam [transformações](#transformacoes "Agrupamentos, filtros e mapeamentos entre os dados") ou [ações](#ações "Contagens e persistências") realizados em um RDD;

3. **Spark Context:** é o que conecta o Spark ao programa que está sendo desenvolvido.

#### Arquitetura
1. **Driver Program:** gerencia a criação e executa o processamento;
2. **Cluster Manager:** responsável por administrar as máquinas utilizas como workers, só é necessário se o Spark for executado de forma distribuída;
3. **Workers:** executarão as tarefas enviadas pelo Driver Program.

### BigQuery

#### O que é
Serviço de Big Data da Google, armazenar seus dados na nuvem no servidor da Google, da até pra utilizar como data warehouse. Por ser serviço da Google, ele te possibilita trabalhar com as outras ferramentas da Google.

### Microsoft Azure

#### O que é
Oferece serviços para computação, armazenamento, análise, redes, etc. 

#### Serviços
1. **Serviços de Computação:** oferece Máquinas Virtuais (VMs), Serviços de aplicativos (App Services), [Kubernetes](#kubernetes "ajuda a criar aplicativos baseados em microsserviços nativos da nuvem"), Azure Functions (computação serverless), etc;
2. **Armazenamento:** oferece soluções de armazenamento para dados estruturados e não estruturados, como Blob Storage (armazenamento de objetos), Azure Files (sistema de arquivos gerenciado), Disk Storage (discos gerenciados para VMs), etc;
3. **Banco de Dados:** os serviços de bancos de dados simplificam a admnistração e a escalabilidade, serviços esses como: Azure SQL Database, Azure Cosmos DB, Azure Database for PostgreSQL, Azure Database for MySQL, etc;
4. **Rede:** os serviços de rede permitem criar e gerenciar redes seguras e de alto desempenho, serviços como: Virtual Network (rede virtual), Load Balancer (balanceador de carga), Azure DNS (Domain Name System), Azure CDN (Content Delivery Network), VPN Gateway, etc;
5. **Inteligência Artificial e Machine Learning:** os serviços oferecem APIs para visão computacional, processamento de linguagem natural, reconhecimento de fala e entre outros. Estes serviços também facilitam a junção de IA e machine learning em aplicativos, serviços como: Azure Machine Learning, Cognitive Services e Bot Services;
6. **Segurança e Conformidade:** serviços para proteger dados e gerenciar a conformidade com regulamentações, recursos: Azure Security Center, Azure Sentinel ([SIEM](#siem "Gerenciamento de Informações e Eventos de Segurança (pt-br)") nativo na nuvem) e Azure Active Directory;
7. **DevOps e Ferramentas de Desenvolvimento:** facilitar a integração contínua e entrega contínua (CI/CD), gestão de código-fonte e colaboração entre equipes de desenvolvimento, serviços: Azure DevOps, GitHub Actions e Azure Pipelines;
8. **Análise de Dados:** os serviços Azure Synapse Analytics, Azure Data Lake, Azure Data Factory e Power BI, permitem análise de grandes volumes de dados e a criação de relatórios detalhados;
9. **IoT:** o Azure IoT Hub, Azure IoT Central e Azure Digital Twins, são serviços que suportam a criação de soluções IoT escaláveis, conectando dispositivos, gerenciando dados de sensores e implementando análises em tempo real;
10. **Híbrido e Multi-Cloud:** o Azure Arc permite a gestão de recursos em ambientes híbridos e [multi-cloud](#multi-cloud " uso de serviços de computação em nuvem de diferentes fornecedores dentro de uma mesma arquitetura e heterogênea").

### Termos
- **Computação distribuida:** sistema que interliga vários computadores, ganhando muito processamento, estes *vários computadores é chamado de cluster, e um computador deste cluster é chamado de nó*;
------------------------------------------------------------------------------------------------------------------------------------------

### **Recursos Utilizados:**
- GitHub
- Engenharia de dados e Big data com Apache Spark // Conceito e terminologias (https://www.youtube.com/watch?v=CPYjUA2UNq8)
- O que é Apache Spark? (https://cloud.google.com/learn/what-is-apache-spark?hl=pt-BR)
- Introdução ao Apache Spark (https://www.devmedia.com.br/introducao-ao-apache-spark/34178)
- O que é o Big Query? (https://www.youtube.com/watch?v=fZkEDWTSfB0)

### **Desafios Encontrados:**  
Compreender alguns termos técnicos.

### **Próximos Passos:**
Terminar de estudar a parte de dados e se possível explorar algumas ferramentas.